{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 월간 데이콘 5, 생체 광학 데이터 분석 AI 경진대회\n",
    "\n",
    "## Public 3rd, Private 3rd / 85 (Top 3.5%)\n",
    "\n",
    "- Competiton link : https://dacon.io/competitions/official/235616/overview/description/\n",
    "- Data : https://dacon.io/competitions/official/235616/data/\n",
    "- This Solution is also uploaded to Dacon Codeshare : https://dacon.io/competitions/official/235616/codeshare/1571?page=1&dtype=recent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import time\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "import warnings ; warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 100000/100000 [00:20<00:00, 4996.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 16000) (100000, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 10000/10000 [00:01<00:00, 5039.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 16000) (100000, 30) (10000, 16000) (10000, 30)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "\n",
    "def data_loader(files):\n",
    "    out = []\n",
    "    for file in tqdm(files):\n",
    "        data, fs = librosa.load(file, sr = None)\n",
    "        out.append(data)\n",
    "    out = np.array(out)\n",
    "    return out\n",
    "\n",
    "Xtrain = glob(data_dir + 'train/*.wav')\n",
    "Xtrain = data_loader(Xtrain)\n",
    "\n",
    "Ytrain = pd.read_csv(data_dir + 'train_answer.csv', index_col='id')\n",
    "submission = pd.read_csv(data_dir + 'submission.csv', index_col='id')\n",
    "\n",
    "print(Xtrain.shape, Ytrain.shape)\n",
    "time.sleep(1)\n",
    "\n",
    "Xtest = glob(data_dir + 'test/*.wav')\n",
    "Xtest = data_loader(Xtest)\n",
    "\n",
    "Xtrain = Xtrain.astype('float32')\n",
    "Xtest = Xtest.astype('float32')\n",
    "\n",
    "print(Xtrain.shape, Ytrain.shape, Xtest.shape, submission.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dB Mel Spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_melspectrogram(data, n_fft, win_length, hop_length, n_mels, sr=16000, save=False, to_db=True, normalize=False):\n",
    "    array = []\n",
    "    for i in tqdm(range(len(data))):\n",
    "        melspec = librosa.feature.melspectrogram(data[i], sr=sr, n_fft=n_fft, win_length=win_length, \n",
    "                                                 hop_length=hop_length,n_mels=n_mels)\n",
    "        array.append(melspec)\n",
    "    array = np.array(array)\n",
    "    if to_db == True:\n",
    "        array = librosa.power_to_db(array, ref = np.max)\n",
    "    if normalize==True: \n",
    "        mean = array.mean()\n",
    "        std = array.std()\n",
    "        array = (array - mean) / std\n",
    "    if save == True:\n",
    "        np.save(f\"{data_dir}mel_spectrogram({n_fft},{win_length},{hop_length},{n_mels}).npy\", array) \n",
    "    return array\n",
    "\n",
    "def gen_4_mels(data, normalize=True):\n",
    "    alpha = get_melspectrogram(data, n_fft=256, win_length=200, hop_length=160, n_mels=64, save=False, to_db=True, normalize=normalize)\n",
    "    beta = get_melspectrogram(data, n_fft=512, win_length=400, hop_length=160, n_mels=64, save=False, to_db=True, normalize=normalize)\n",
    "    gamma = get_melspectrogram(data, n_fft=1024, win_length=800, hop_length=160, n_mels=64, save=False, to_db=True, normalize=normalize)\n",
    "    delta = get_melspectrogram(data, n_fft=2048, win_length=1600, hop_length=160, n_mels=64, save=False, to_db=True, normalize=normalize)\n",
    "    \n",
    "    data = np.stack([alpha, beta, gamma, delta], axis=-1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Junho Sun 음성 신호 기본 정보 CodeShare : https://dacon.io/competitions/official/235616/codeshare/1305?page=1&dtype=recent&ptype=pub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "글 내용 중에서 마지막 부분에 mel spectrogram 의 win_length 를 설명해주시는 부분이 있습니다.  \n",
    "'마지막으로 spectrogram과 melspectrogram의 해상력에 대해 설명하겠습니다. win_length가 커질수록 주파수 성분에 대한 해상력은 높아지지만, 즉 더 정밀해지지만, 시간 성분에 대한 해상력은 낮아지게 됩니다. 즉, 더 정밀한 주파수 분포를 얻을 수 있으나 시간에 따른 주파수 변화를 관찰하기가 어려워집니다. 반대로 win_length가 작은 경우에는 주파수 성분에 대한 해상력은 낮아지지만, 시간 성분에 대한 해상력은 높아지게 됩니다. 따라서 적절한 값을 찾는 것이 중요합니다.'  \n",
    "음성 신호의 시간 성분과 주파수 성분을 어떻게 둘다 놓치지 않고 잡아낼 수 있을까 고민하다가, 서로 다른 win_length 를 가진 여러개의 스펙트럼을 겹쳐가지고 4개의 mel spectrogram 을 만들어서 겹쳤습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110000, 16000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 110000/110000 [01:54<00:00, 961.62it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 110000/110000 [02:28<00:00, 738.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 110000/110000 [03:38<00:00, 503.89it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 110000/110000 [05:59<00:00, 305.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 64, 101, 4) (100000, 30) (10000, 64, 101, 4)\n"
     ]
    }
   ],
   "source": [
    "all_data = np.concatenate([Xtrain, Xtest], axis=0)\n",
    "print(all_data.shape)\n",
    "time.sleep(1)\n",
    "all_dbmel = gen_4_mels(all_data, normalize=True)\n",
    "Xtrain_dbmel = all_dbmel[:len(Ytrain)]\n",
    "Xtest_dbmel = all_dbmel[len(Ytrain):]\n",
    "print(Xtrain_dbmel.shape, Ytrain.shape, Xtest_dbmel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Convolution2D, BatchNormalization, Activation, Flatten, Dropout, Dense, Add, AveragePooling2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.losses import KLDivergence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.optimizers import Nadam\n",
    "\n",
    "def mish(x):\n",
    "    return x * K.tanh(K.softplus(x))\n",
    "\n",
    "def eval_kldiv(y_true, y_pred):\n",
    "    return KLDivergence()(np.array(y_true).astype('float32'), np.array(y_pred).astype('float32')).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 64, 101, 4)] 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 64, 101, 32)  1184        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 64, 101, 32)  128         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 64, 101, 32)  0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 101, 32)  9248        activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 101, 32)  128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 101, 32)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 101, 32)  9248        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 101, 32)  128         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 64, 101, 32)  0           batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 101, 32)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 32, 50, 32)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 32, 50, 32)   0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 50, 64)   18496       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 32, 50, 64)   256         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 32, 50, 64)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 50, 64)   36928       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 50, 64)   256         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 50, 64)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 32, 50, 64)   36928       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 50, 64)   256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 50, 64)   0           batch_normalization_5[0][0]      \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 50, 64)   0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 16, 25, 64)   0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 16, 25, 64)   0           average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 25, 128)  73856       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 25, 128)  512         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 25, 128)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 16, 25, 128)  147584      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 25, 128)  512         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16, 25, 128)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 25, 128)  147584      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 16, 25, 128)  512         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 16, 25, 128)  0           batch_normalization_8[0][0]      \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 16, 25, 128)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 8, 12, 128)   0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 8, 12, 128)   0           average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 8, 12, 64)    8256        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 8, 12, 64)    36928       conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 12, 256)   16640       conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 8, 12, 256)   1024        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 8, 12, 256)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 12, 64)    16448       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 8, 12, 64)    36928       conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 8, 12, 256)   16640       conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 8, 12, 256)   1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 8, 12, 256)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 8, 12, 64)    16448       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 8, 12, 64)    36928       conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 8, 12, 256)   16640       conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 8, 12, 256)   1024        conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 8, 12, 256)   0           batch_normalization_11[0][0]     \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 8, 12, 256)   0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 4, 6, 256)    0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 4, 6, 256)    0           average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 4, 6, 128)    32896       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 4, 6, 128)    147584      conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 4, 6, 512)    66048       conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 4, 6, 512)    2048        conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 4, 6, 512)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 4, 6, 128)    65664       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 4, 6, 128)    147584      conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 4, 6, 512)    66048       conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 4, 6, 512)    2048        conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 4, 6, 512)    0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 4, 6, 128)    65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 4, 6, 128)    147584      conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 4, 6, 512)    66048       conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 4, 6, 512)    2048        conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 4, 6, 512)    0           batch_normalization_14[0][0]     \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 4, 6, 512)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 2, 3, 512)    0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 2, 3, 512)    0           average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 3072)         0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          393344      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 128)          512         dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 128)          0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          16512       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 128)          512         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 128)          0           batch_normalization_15[0][0]     \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 128)          0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128)          0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 30)           3870        dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,914,686\n",
      "Trainable params: 1,908,222\n",
      "Non-trainable params: 6,464\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_fn():\n",
    "    dropout_rate=0.5\n",
    "    \n",
    "    model_in = Input(shape = (Xtrain_dbmel.shape[1:]))\n",
    "    x = Convolution2D(32, 3, padding='same', kernel_initializer='he_normal')(model_in)\n",
    "    x = BatchNormalization()(x)\n",
    "    x_res = x\n",
    "    x = Activation(mish)(x)\n",
    "    x = Convolution2D(32, 3, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(mish)(x)\n",
    "    x = Convolution2D(32, 3, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, x_res])\n",
    "    x = Activation(mish)(x)\n",
    "    x = AveragePooling2D()(x)\n",
    "    x = Dropout(rate=dropout_rate)(x)\n",
    "\n",
    "    x = Convolution2D(64, 3, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x_res = x\n",
    "    x = Activation(mish)(x)\n",
    "    x = Convolution2D(64, 3, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(mish)(x)\n",
    "    x = Convolution2D(64, 3, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, x_res])\n",
    "    x = Activation(mish)(x)\n",
    "    x = AveragePooling2D()(x)\n",
    "    x = Dropout(rate=dropout_rate)(x)\n",
    "\n",
    "    x = Convolution2D(128, 3, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x_res = x\n",
    "    x = Activation(mish)(x)\n",
    "    x = Convolution2D(128, 3, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(mish)(x)\n",
    "    x = Convolution2D(128, 3, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, x_res])\n",
    "    x = Activation(mish)(x)\n",
    "    x = AveragePooling2D()(x)\n",
    "    x = Dropout(rate=dropout_rate)(x)\n",
    "\n",
    "    x = Convolution2D(64, 1, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = Convolution2D(64, 3, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = Convolution2D(256, 1, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x_res = x\n",
    "    x = Activation(mish)(x)\n",
    "    x = Convolution2D(64, 1, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = Convolution2D(64, 3, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = Convolution2D(256, 1, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(mish)(x)\n",
    "    x = Convolution2D(64, 1, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = Convolution2D(64, 3, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = Convolution2D(256, 1, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, x_res])\n",
    "    x = Activation(mish)(x)\n",
    "    x = AveragePooling2D()(x)\n",
    "    x = Dropout(rate=dropout_rate)(x)\n",
    "\n",
    "    x = Convolution2D(128, 1, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = Convolution2D(128, 3, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = Convolution2D(512, 1, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x_res = x\n",
    "    x = Activation(mish)(x)\n",
    "    x = Convolution2D(128, 1, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = Convolution2D(128, 3, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = Convolution2D(512, 1, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(mish)(x)\n",
    "    x = Convolution2D(128, 1, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = Convolution2D(128, 3, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = Convolution2D(512, 1, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x, x_res])\n",
    "    x = Activation(mish)(x)\n",
    "    x = AveragePooling2D()(x)\n",
    "    x = Dropout(rate=dropout_rate)(x)\n",
    "\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(units=128, kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x_res = x\n",
    "    x = Activation(mish)(x)\n",
    "    x = Dropout(rate=dropout_rate)(x)\n",
    "\n",
    "    x = Dense(units=128, kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Add()([x_res, x])\n",
    "    x = Activation(mish)(x)\n",
    "    x = Dropout(rate=dropout_rate)(x)\n",
    "\n",
    "    model_out = Dense(units=30, activation='softmax')(x)\n",
    "    model = Model(model_in, model_out)\n",
    "    model.compile(loss=KLDivergence(), optimizer=Nadam(learning_rate=0.002))\n",
    "    return model\n",
    "build_fn().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train 15 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models=15\n",
    "model_list=[]\n",
    "\n",
    "for i in tqdm(range(num_models)):\n",
    "    model = build_fn()\n",
    "    model.fit(Xtrain_dbmel, Ytrain, epochs=187, batch_size=16)\n",
    "    model_list.append(model)\n",
    "    model.save(f\"model_{i}.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습을 하고, 모델 저장. 모델 저장 후 모두 불러와서 단순 평균 앙상블 진행. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:14<00:00,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 models reloaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for i in tqdm(range(0, 15)):\n",
    "    model_name = f\"model_{i}.h5\"\n",
    "    models.append(keras.models.load_model(model_name, custom_objects={'mish' : mish}))\n",
    "print(f\"{len(models)} models reloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 Evaluation Score : 0.24118183553218842\n",
      "Model 2 Evaluation Score : 0.23312652111053467\n",
      "Model 3 Evaluation Score : 0.24818634986877441\n",
      "Model 4 Evaluation Score : 0.23722496628761292\n",
      "Model 5 Evaluation Score : 0.2390882819890976\n",
      "Model 6 Evaluation Score : 0.24100100994110107\n",
      "Model 7 Evaluation Score : 0.2496347874403\n",
      "Model 8 Evaluation Score : 0.24356740713119507\n",
      "Model 9 Evaluation Score : 0.24107488989830017\n",
      "Model 10 Evaluation Score : 0.2274245172739029\n",
      "Model 11 Evaluation Score : 0.23607350885868073\n",
      "Model 12 Evaluation Score : 0.23797260224819183\n",
      "Model 13 Evaluation Score : 0.2538020610809326\n",
      "Model 14 Evaluation Score : 0.23577089607715607\n",
      "Model 15 Evaluation Score : 0.2238369584083557\n",
      "\n",
      "Mean Predictions Evaluation Score : 0.18654921650886536\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bed</th>\n",
       "      <th>bird</th>\n",
       "      <th>cat</th>\n",
       "      <th>dog</th>\n",
       "      <th>down</th>\n",
       "      <th>eight</th>\n",
       "      <th>five</th>\n",
       "      <th>four</th>\n",
       "      <th>go</th>\n",
       "      <th>happy</th>\n",
       "      <th>...</th>\n",
       "      <th>sheila</th>\n",
       "      <th>six</th>\n",
       "      <th>stop</th>\n",
       "      <th>three</th>\n",
       "      <th>tree</th>\n",
       "      <th>two</th>\n",
       "      <th>up</th>\n",
       "      <th>wow</th>\n",
       "      <th>yes</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.024768</td>\n",
       "      <td>0.002820</td>\n",
       "      <td>0.000914</td>\n",
       "      <td>0.003068</td>\n",
       "      <td>0.003746</td>\n",
       "      <td>0.255225</td>\n",
       "      <td>0.002023</td>\n",
       "      <td>0.002626</td>\n",
       "      <td>0.083618</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>0.001561</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>0.248279</td>\n",
       "      <td>0.009439</td>\n",
       "      <td>0.008524</td>\n",
       "      <td>0.002312</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.278987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.147262</td>\n",
       "      <td>0.000757</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>0.073441</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>0.003424</td>\n",
       "      <td>0.256637</td>\n",
       "      <td>0.221761</td>\n",
       "      <td>0.013797</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.000314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.000923</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>0.027174</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.001806</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.257953</td>\n",
       "      <td>0.326719</td>\n",
       "      <td>0.003251</td>\n",
       "      <td>0.001538</td>\n",
       "      <td>0.284989</td>\n",
       "      <td>0.004832</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.004637</td>\n",
       "      <td>0.002297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.000946</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.290618</td>\n",
       "      <td>0.282772</td>\n",
       "      <td>0.000797</td>\n",
       "      <td>0.032753</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.004130</td>\n",
       "      <td>0.266848</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.018497</td>\n",
       "      <td>0.001371</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002120</td>\n",
       "      <td>0.000584</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.133227</td>\n",
       "      <td>0.011718</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.013705</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.003437</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>0.021904</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.000975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.013062</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.001726</td>\n",
       "      <td>0.123044</td>\n",
       "      <td>0.007379</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.247560</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.040355</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>0.001081</td>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>0.258006</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.000967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.003452</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.006914</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.002741</td>\n",
       "      <td>0.287367</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.332798</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.001652</td>\n",
       "      <td>0.002893</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.014695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000968</td>\n",
       "      <td>0.246415</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.303059</td>\n",
       "      <td>0.016404</td>\n",
       "      <td>0.012524</td>\n",
       "      <td>0.000826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015037</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.034002</td>\n",
       "      <td>0.011572</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.294591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.006805</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.039188</td>\n",
       "      <td>0.006068</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.402306</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>0.001361</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.000720</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.005782</td>\n",
       "      <td>0.006733</td>\n",
       "      <td>0.000390</td>\n",
       "      <td>0.000160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001426</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.172990</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.005990</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.116582</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.003889</td>\n",
       "      <td>0.009046</td>\n",
       "      <td>0.000981</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>0.004641</td>\n",
       "      <td>0.018064</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.015860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         bed      bird       cat       dog      down     eight      five  \\\n",
       "id                                                                         \n",
       "0   0.024768  0.002820  0.000914  0.003068  0.003746  0.255225  0.002023   \n",
       "1   0.147262  0.000757  0.000718  0.000272  0.000212  0.000788  0.073441   \n",
       "2   0.000841  0.000384  0.000923  0.000784  0.001234  0.027174  0.000816   \n",
       "3   0.000871  0.001050  0.000946  0.000380  0.000642  0.000768  0.290618   \n",
       "4   0.002120  0.000584  0.000557  0.133227  0.011718  0.000677  0.013705   \n",
       "5   0.013062  0.001301  0.001726  0.123044  0.007379  0.000795  0.247560   \n",
       "6   0.003452  0.000936  0.000672  0.006914  0.001613  0.000342  0.000566   \n",
       "7   0.000968  0.246415  0.000587  0.000717  0.002379  0.000920  0.303059   \n",
       "8   0.006805  0.001124  0.000614  0.039188  0.006068  0.000433  0.402306   \n",
       "9   0.001426  0.000900  0.000603  0.002688  0.172990  0.000954  0.005990   \n",
       "\n",
       "        four        go     happy  ...    sheila       six      stop     three  \\\n",
       "id                                ...                                           \n",
       "0   0.002626  0.083618  0.000695  ...  0.001235  0.001561  0.001605  0.248279   \n",
       "1   0.000204  0.000677  0.000331  ...  0.000386  0.000305  0.000819  0.003424   \n",
       "2   0.000743  0.001806  0.000982  ...  0.000432  0.257953  0.326719  0.003251   \n",
       "3   0.282772  0.000797  0.032753  ...  0.000579  0.000348  0.000802  0.004130   \n",
       "4   0.000852  0.001960  0.000489  ...  0.000196  0.000568  0.003437  0.000297   \n",
       "5   0.003694  0.040355  0.000491  ...  0.000189  0.000313  0.001260  0.001081   \n",
       "6   0.002741  0.287367  0.000375  ...  0.000485  0.000763  0.332798  0.000449   \n",
       "7   0.016404  0.012524  0.000826  ...  0.015037  0.000395  0.001994  0.002466   \n",
       "8   0.000824  0.001989  0.001361  ...  0.000097  0.000190  0.000720  0.000534   \n",
       "9   0.019100  0.116582  0.000774  ...  0.000444  0.003889  0.009046  0.000981   \n",
       "\n",
       "        tree       two        up       wow       yes      zero  \n",
       "id                                                              \n",
       "0   0.009439  0.008524  0.002312  0.000764  0.000609  0.278987  \n",
       "1   0.256637  0.221761  0.013797  0.000204  0.000234  0.000314  \n",
       "2   0.001538  0.284989  0.004832  0.000346  0.004637  0.002297  \n",
       "3   0.266848  0.001172  0.018497  0.001371  0.000299  0.000682  \n",
       "4   0.000145  0.000149  0.002382  0.021904  0.000615  0.000975  \n",
       "5   0.000391  0.000619  0.002737  0.258006  0.000419  0.000967  \n",
       "6   0.000190  0.001652  0.002893  0.000720  0.000614  0.014695  \n",
       "7   0.000954  0.034002  0.011572  0.003346  0.000413  0.294591  \n",
       "8   0.000143  0.000185  0.005782  0.006733  0.000390  0.000160  \n",
       "9   0.000260  0.000621  0.004641  0.018064  0.000582  0.015860  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = np.zeros(shape=submission.shape)\n",
    "train_preds = np.zeros(shape = Ytrain.shape)\n",
    "\n",
    "train_preds_list=[]\n",
    "test_preds_list=[]\n",
    "score_list=[]\n",
    "\n",
    "for model, i in zip(models, range(len(models))):\n",
    "    a = model.predict(Xtrain_dbmel)\n",
    "    b = model.predict(Xtest_dbmel)\n",
    "    eval_score = eval_kldiv(Ytrain, a)\n",
    "    \n",
    "    print(f\"Model {i+1} Evaluation Score : {eval_score}\")\n",
    "    train_preds = train_preds + a\n",
    "    preds = preds + b\n",
    "    \n",
    "    train_preds_list.append(a)\n",
    "    test_preds_list.append(b)\n",
    "    score_list.append(eval_score)\n",
    "    \n",
    "train_preds = train_preds / len(models)\n",
    "preds = preds / len(models)\n",
    "print(f\"\\nMean Predictions Evaluation Score : {eval_kldiv(Ytrain, train_preds)}\")\n",
    "simple_average = pd.DataFrame(preds, index=submission.index, columns=submission.columns)\n",
    "simple_average.to_csv('15 Average Ensemble model.csv')\n",
    "simple_average.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple Average of 15 Predictions  \n",
    "- Public LB : 0.399484\n",
    "- Private LB : 0.39202"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
